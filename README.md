# Word2Vec-Word-Embedding-

This is my try at implementing Word2Vec word embeddings using One hot encoding vectors(CBOG) using Softmax Activation function, Cross-Entropy loss function and Adam optimizer

**Technologies used** - Keras and TensorFlow and Numpy

**Dataset** - Large Movie Review Dataset(IMDB) from Stanford. The data includes movie reviews along with
their associated binary sentiment polarity labels. The core dataset contains 50,000 reviews split
evenly into 25k train and 25k test sets. The overall distribution of labels is balanced (25k pos and
25k neg).
